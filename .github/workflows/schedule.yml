name: Scraper Diario BeneficiosSUBE

on:
  schedule:
    - cron: '0 11 * * *'
  workflow_dispatch:

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    steps:
    - name: Descargar repositorio
      uses: actions/checkout@v3

    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        playwright install chromium # Instalamos el navegador necesario

    - name: Ejecutar Scraper (ETL)
      run: python main.py

    - name: Guardar cambios (Base de Datos y Logs)
      run: |
        git config --global user.name 'BeneficiosBot'
        git config --global user.email 'bot@noreply.github.com'
        git add data/beneficios.db logs/scraper.log
        # Solo hacemos commit si hay cambios reales
        git diff --quiet && git diff --staged --quiet || (git commit -m "Actualización automática de beneficios: $(date +'%Y-%m-%d')" && git push)