# ğŸ’³ BeneficiosSUBE

### Centralizador inteligente de beneficios para SUBE

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-API-success)
![SQLite](https://img.shields.io/badge/Database-SQLite-lightgrey)
![Playwright](https://img.shields.io/badge/Scraping-Playwright-orange)
![CI](https://img.shields.io/badge/GitHub_Actions-Automated-brightgreen)
![Status](https://img.shields.io/badge/Status-Active-success)

---

## Â¿QuÃ© es BeneficiosSUBE?

**BeneficiosSUBE** es una plataforma que **centraliza, normaliza y visualiza** los beneficios de transporte pÃºblico (SUBE) ofrecidos por **bancos y billeteras virtuales**, los cuales hoy se encuentran **fragmentados, mal estructurados o poco accesibles** en mÃºltiples sitios web.

El proyecto automatiza la recolecciÃ³n de estos datos usando **Web Scraping avanzado**, los transforma en informaciÃ³n limpia y estructurada, y los expone a travÃ©s de una **interfaz web simple y entendible para cualquier usuario**.

> Pensado desde el punto de vista de la **persona comÃºn**, no del banco.

---

## MotivaciÃ³n del Proyecto

Hoy, una persona que quiere saber:

* QuÃ© banco le devuelve mÃ¡s viajando en colectivo
* QuÃ© dÃ­as conviene usar determinada billetera
* Si un beneficio aplica en su provincia

Tiene que:

* Recorrer mÃºltiples webs,
* Leer letras chicas,
* Interpretar condiciones poco claras.

**BeneficiosSUBE resuelve ese problema**, convirtiendo informaciÃ³n dispersa y â€œsuciaâ€ en **datos claros, comparables y accesibles**.

---

## Arquitectura General (ETL)

El sistema sigue un enfoque **ETL automatizado**, orientado a datos reales y no ideales.

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Webs     â”‚  Bancos / Fintechs
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scrapers   â”‚  Playwright (SPA, JS dinÃ¡mico)
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transform  â”‚  Limpieza, normalizaciÃ³n, deduplicaciÃ³n
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SQLite DB  â”‚  Modelo relacional normalizado
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI    â”‚  API REST
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Web UI     â”‚  SPA JS Vanilla
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Modelo de Datos (DER)

DiseÃ±o relacional normalizado para garantizar integridad y escalabilidad.

**Entidades principales:**

* **Entidad_Emisora**

  * Bancos y billeteras
  * Logo
  * Color institucional

* **Alcance_Geografico**

  * Provincia / Ciudad
  * Tipo de transporte (Colectivo / Subte)

* **Vigencia_Temporal**

  * DÃ­as de la semana
  * PerÃ­odos promocionales

* **Beneficio**

  * Descuento
  * Tope
  * Condiciones
  * RelaciÃ³n con las entidades anteriores

---

## Stack TecnolÃ³gico

### Backend

* Python 3.10+
* FastAPI
* Uvicorn

### Scraping

* Playwright
* Playwright-Stealth
* Manejo de SPAs y carga dinÃ¡mica

### Base de Datos

* SQLite (modelo relacional)

### Frontend

* HTML5
* CSS3 (Grid / Flexbox)
* JavaScript Vanilla

### DevOps / AutomatizaciÃ³n

* GitHub Actions
* Git Scraping programado

---

## InstalaciÃ³n y Uso

### 1ï¸âƒ£ Requisitos

* Python 3.10+
* Git

---

### 2ï¸âƒ£ Clonar y configurar entorno

```bash
git clone https://github.com/tu-usuario/beneficiosSube.git
cd beneficiosSube
```

```bash
python -m venv .venv
```

Activar entorno:

**Windows**

```bash
.venv\Scripts\activate
```

**Linux / macOS**

```bash
source .venv/bin/activate
```

Instalar dependencias:

```bash
pip install -r requirements.txt
playwright install chromium
```

---

### 3ï¸âƒ£ EjecuciÃ³n

**Ejecutar ETL completo (scraping + carga):**

```bash
python main.py
```

**Levantar interfaz web:**

```bash
uvicorn web.main:app --reload
```

Abrir en el navegador:

```
http://127.0.0.1:8000
```

---

## AutomatizaciÃ³n (GitHub Actions)

El proyecto incluye un workflow de **Git Scraping** en:

```
.github/workflows/schedule.yml
```

Se ejecuta **todos los dÃ­as a las 08:00 AM** y:

* Inicializa entorno Linux
* Ejecuta scrapers
* Actualiza `beneficios.db`
* Commits automÃ¡ticos con nuevos datos

El repositorio **se actualiza solo**, sin intervenciÃ³n humana.

---

## Estructura del Proyecto

```text
beneficiosSube/
â”œâ”€â”€ data/               # SQLite + JSON procesados
â”œâ”€â”€ loaders/            # InserciÃ³n y normalizaciÃ³n SQL
â”œâ”€â”€ logs/               # Logs de scraping
â”œâ”€â”€ scrapers/           # ExtracciÃ³n Playwright
â”œâ”€â”€ utils/              # ConfiguraciÃ³n de entidades (logos, colores, URLs)
â”œâ”€â”€ web/                # FastAPI + UI
â””â”€â”€ main.py             # Orquestador ETL
```

---

## Enfoque del Proyecto

* Datos reales y desordenados
* Problema cotidiano
* AutomatizaciÃ³n completa
* Escalable a nuevas entidades
* Pensado para usuarios no tÃ©cnicos

---

## Proximas Extensiones...

* Filtros por provincia
* Comparador de bancos
* Historial de beneficios
* API pÃºblica
* Dashboard analÃ­tico