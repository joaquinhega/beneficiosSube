import asyncio
import json
import logging
import os
from playwright.async_api import async_playwright
from playwright_stealth import Stealth

# Configuraci√≥n de Logs (Tarea: Manejo de Excepciones)
if not os.path.exists('logs'): os.makedirs('logs')
logging.basicConfig(filename='logs/scraper.log', level=logging.INFO, 
                    format='%(asctime)s - %(levelname)s - %(message)s')

async def extractor_crudo(page, url):
    """M√≥dulo 1.2: Extrae el texto bruto de una URL espec√≠fica."""
    try:
        await page.goto(url, wait_until="domcontentloaded", timeout=20000)
        # Extraemos todo el texto del cuerpo de la p√°gina
        return await page.inner_text("body")
    except Exception as e:
        logging.error(f"Falla al extraer texto crudo en {url}: {e}")
        return ""

async def discovery_bot(p, banco_config):
    """M√≥dulo 1.1: Recorre la landing y detecta links clave."""
    nombre = banco_config['nombre']
    url_landing = banco_config['url']
    selector_promo = banco_config['selector']
    
    # Implementaci√≥n de Bloque Try-Except por Fuente
    try:
        print(f"üöÄ Iniciando Discovery en {nombre}...")
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(viewport={'width': 1920, 'height': 1080})
        page = await context.new_page()
        
        await page.goto(url_landing, wait_until="commit")
        await page.wait_for_selector(selector_promo, timeout=15000)
        
        elementos = await page.query_selector_all(selector_promo)
        beneficios_detectados = []

        for el in elementos:
            texto_breve = await el.inner_text()
            # Filtro: SUBE o Transporte
            if any(key in texto_breve.upper() for key in ["SUBE", "TRANSPORTE", "COLECTIVO", "BENCINA"]):
                link = await el.query_selector("a")
                href = await link.get_attribute("href") if link else url_landing
                
                # M√≥dulo 1.2: Entrar y extraer texto crudo
                print(f"  üîó Entrando a detalle: {texto_breve[:30]}...")
                raw_data = await extractor_crudo(page, href)
                
                beneficios_detectados.append({
                    "banco": nombre,
                    "keyword_match": texto_breve.strip(),
                    "url": href,
                    "raw_text": raw_data[:500] # Guardamos solo los primeros 500 caracteres
                })
        
        await browser.close()
        return beneficios_detectados

    except Exception as e:
        # Manejo de excepciones: Registra y permite continuar con otro banco
        logging.error(f"Error cr√≠tico en m√≥dulo de {nombre}: {e}")
        print(f"‚ö†Ô∏è {nombre} fall√≥, pero el proceso contin√∫a. Revisar logs.")
        return []

async def main():
    configs = [
        {"nombre": "Galicia", "url": "https://www.galicia.ar/personas/promociones", "selector": "div.card-beneficio"},
        {"nombre": "Santander", "url": "https://www.santander.com.ar/personas/beneficios#/", "selector": "div[class*='sc-fEXmlR']"}
    ]

    async with Stealth().use_async(async_playwright()) as p:
        todas_las_promos = []
        for conf in configs:
            resultado = await discovery_bot(p, conf)
            todas_las_promos.extend(resultado)

        # Guardar resultados del Prototipo
        with open("data/raw_extraction.json", "w", encoding="utf-8") as f:
            json.dump(todas_las_promos, f, indent=4, ensure_ascii=False)
        
        print(f"\n‚úÖ Sprint 1 finalizado. Datos crudos guardados en 'data/raw_extraction.json'.")

if __name__ == "__main__":
    asyncio.run(main())